data:
  bin_dir: datasets
  bin_file: mel_spectrograms.h5
  data_key: mel_spectrograms
  lazy_load: true
  raw_dir: datasets/gin
  max_samples: 100
  sample_percentage: null
  variable_length: true
  
audio:
  sample_rate: 22050
  n_fft: 1024
  hop_length: 256
  win_length: 1024
  n_mels: 80
  fmin: 0
  fmax: 8000
  f0_min: 50
  f0_max: 600
  max_audio_length: 5.0  # Shorter audio segments for faster training

model:
  # VAE parameters
  vae:
    encoder_channels: [16, 32, 64]  # Smaller channel progression
    decoder_channels: [64, 32, 16]
    latent_channels: 32
    latent_dim: 16
    kl_weight: 0.001  # Very small to prioritize reconstruction
    
  # Diffusion parameters
  diffusion:
    diffusion_steps: 50  # Reduced steps for faster training
    beta_schedule: "linear"
    beta_start: 0.0001
    beta_end: 0.02
    
  # Conditioning parameters
  conditioning:
    f0_embedding_dim: 64
    phone_embedding_dim: 128
    midi_embedding_dim: 64
    duration_embedding_dim: 32
    condition_channels: 128
    cross_attention_heads: 4
    cross_attention_dim: 64
    
  time_frames: 432  # ~5 seconds at 22050Hz/256 hop
  mel_bins: 80

train:
  batch_size: 16
  accumulate_grad_batches: 1
  num_epochs: 100
  learning_rate: 0.0005
  weight_decay: 0.0001
  lr_scheduler: reduce_on_plateau
  lr_patience: 5
  lr_factor: 0.7
  validation_split: 0.1
  log_interval: 100
  save_dir: logs/latent_diffusion
  num_workers: 4
  pin_memory: true
  precision: '16-mixed'  # Use mixed precision for faster training
  
validation:
  val_every_epoch: 5
  max_samples: 4
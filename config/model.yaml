# config/model.yaml

data:
  bin_dir: datasets
  bin_file: mel_spectrograms.h5
  mel_key: mel_spectrogram # Key for target mel spectrograms (Updated based on preprocess.py)
  phoneme_key: phone_sequence # Key for input phoneme sequences (Updated based on preprocess.py)
  duration_key: adjusted_durations # Key for input duration sequences (Updated based on preprocess.py)
  f0_key: f0_contour        # Key for input F0 sequences (Updated based on preprocess.py)
  midi_pitch_key: midi_pitch_estimated # Key for estimated MIDI pitch
  lazy_load: true
  raw_dir: datasets/gin
  # max_samples: 100 # Set to null or remove to use full dataset
  sample_percentage: null
  variable_length: true
  min_phones_in_lab: 5 # Minimum number of phone entries required in a .lab file to process it

audio:
  sample_rate: 22050
  n_fft: 2048 # Increased from 1024 to increase n_freqs for mel filters
  hop_length: 256
  win_length: 2048 # Set equal to n_fft
  n_mels: 80 # Changed back to 80, should be okay with n_fft=2048 and fmax=null
  fmin: 0
  fmax: null # Set to null (None) to use default sample_rate / 2, ensuring filters cover full range up to Nyquist
  f0_min: 50
  f0_max: 600
  max_audio_length: 10.0

# Model specific parameters
model:
  name: ProgressiveSVS # New model name
  mel_bins: 80        # Shared: Output dimension (MUST match audio.n_mels)
  vocab_size: null    # Shared: Will be dynamically set from data

  # --- ProgressiveSVS Specific Parameters ---
  # Embedding dimensions (Adjust as needed)
  f0_embed_dim: 64
  phone_embed_dim: 256
  midi_embed_dim: 64
  unvoiced_embed_dim: 16 # Dimension for unvoiced flag embedding
  # Resolution scaling factors (relative to full mel_bins)
  # Example: low_res_scale=4 means low-res has mel_bins/4 frequency bins
  low_res_scale: 4
  mid_res_scale: 2

  # Channel configurations for each stage (Adjust based on complexity/memory)
  # Format: List of output channels for each ConvBlock in the stage
  low_res_channels: [256, 256, 128]
  mid_res_channels: [128, 128, 64]
  high_res_channels: [64, 64, 32] # Updated channel config

  # --- Progressive Vocoder (NEW - For Stage 1 Experiment) ---
  progressive_vocoder:
    type: 'ProgressiveVocoder_v1' # Identifier
    # Calculate based on low_res_scale: mel_bins / low_res_scale = 80 / 4 = 20 # Changed back
    input_mel_bins: 20 # MUST match model.mel_bins / model.low_res_scale
    # --- Progressive Vocoder Stages ---
    # Stage 1 (Mel -> Low SR Audio)
    v1_initial_upsample_factor: 128 # Upsample time dim (Aligned with SVS: 512 / (2*2))
    v1_channels: [128, 64]        # Example channels for V1 convs
    v1_kernel_size: 7             # Example kernel size
    v1_output_sr_divisor: 4       # Example: Target SR / 4 = 22050 / 4 = 5512.5 (adjust based on implementation)
    # Stage 2 (Low SR -> Mid SR Audio)
    v2_upsample_factor: 2         # Upsample audio by 2x (Aligned with SVS Stage 1->2 Freq Upsample)
    v2_channels: [64, 32]         # Example channels for V2 convs/resblocks
    v2_kernel_size: 5             # Example kernel size
    v2_num_res_blocks: 3          # Example: Use residual blocks
    v2_output_sr_divisor: 2       # Example: Target SR / 2 = 11025
    # Stage 3 (Mid SR -> Full SR Audio)
    v3_upsample_factor: 2         # Upsample audio by 2x (Aligned with SVS Stage 2->3 Freq Upsample)
    v3_channels: [32, 16]         # Example channels for V3 convs/resblocks
    v3_kernel_size: 3             # Example kernel size
    v3_num_res_blocks: 5          # Example: Use residual blocks
    # --- End Progressive Vocoder Stages ---

  # --- Multi-band Config (NEW) ---
  num_bands_stage1: 2                 # Default for multi-band output projection
  num_bands_stage2: 3
  band_processing_stage2: 'separate' # Options: 'separate', 'shared'
  num_bands_stage3: 4                 # Default, same as stage 2
  band_processing_stage3: 'separate'    # Default, same as stage 2
  # --- End Multi-band Config ---

  # Initial training stage (1, 2, or 3)
  current_stage: 1

# Training Configuration
  stage1_use_vocoder: true # NEW: Enable Stage 1 vocoder training experiment
train:
  batch_size: 16        # Adjust based on GPU memory
  unvoiced_weight: 0.5  # Weight for unvoiced frames in loss calculation (NEW)
  epochs_per_stage:
    stage1: 10         #ideal 200
    stage2: 120         #ideal 150
    stage3: 100         #ideal 150
  
  val_interval: 1       # Run validation every N epochs
  log_dir: logs         # Base directory for all logs
  tensorboard_log_dir: tensorboard # Subdirectory for TensorBoard logs
  checkpoint_dir: checkpoints # Subdirectory for model checkpoints
  num_workers: 4        # DataLoader workers
  log_spectrogram_every_n_val_steps: 5 # Log spectrogram comparison every N validation steps

  # --- Stage-Specific Learning Rates ---
  learning_rate_per_stage:
    stage1: 0.0005  # Example LR for stage 1 (Adjusted from 0.001)
    stage2: 0.0007  # Example LR for stage 2
    stage3: 0.0009  # Example LR for stage 3
  # --- End Stage-Specific Learning Rates ---

  # --- Global Optimizer/Scheduler Params ---
  weight_decay: 0.0001    # Adam weight decay
  lr_factor: 0.5          # Factor by which the learning rate will be reduced (scheduler)
  lr_patience: 10         # Number of epochs with no improvement after which learning rate will be reduced (scheduler)
  # gradient_clip_val: 1.0 # Optional: Gradient clipping value
  freeze_loaded_weights: false # Default: Freeze weights when loading from ckpt

  # log_interval defines log_every_n_steps in Trainer
  log_interval: 50        # Log training metrics every N steps

  # --- Audio Loss Config (NEW - For Stage 1 Vocoder Experiment) ---
  audio_loss_type: 'stft' # Options: 'stft', 'multi_stft', 'l1_wav', etc.
  stft_loss_params: # Example if using STFT loss
    fft_sizes: [1024, 2048, 512]
    hop_sizes: [120, 240, 50] # Must be less than fft_sizes
    win_lengths: [600, 1200, 240] # Must be less than or equal to fft_sizes
    loss_mag_weight: 1.0 # Weight for spectral magnitude loss component
    loss_sc_weight: 1.0  # Weight for spectral convergence loss component
  # --- End Audio Loss Config ---

  # Removed: GAN specific params (lr_g, lr_d, betas, lambda_recon)
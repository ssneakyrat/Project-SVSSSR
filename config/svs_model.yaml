# SVS Model Configuration
# Designed for modular training and inference

# Audio parameters
audio:
  sample_rate: 22050
  n_fft: 1024
  hop_length: 256
  win_length: 1024
  n_mels: 80
  fmin: 0
  fmax: 8000
  f0_min: 50
  f0_max: 600
  max_audio_length: 5.0  # in seconds

# Data configuration
data:
  dataset:
    bin_dir: datasets
    bin_file: mel_spectrograms.h5
    data_key: mel_spectrograms
    
    # Data loading options
    lazy_load: true
    variable_length: true
    max_samples: null  # Use all samples by default
    validation_split: 0.1
    
    # Raw data directories for preprocessing
    raw_dir: datasets/raw
    
  # Sequence dimensions
  sequence:
    max_mel_frames: 432  # ~5 seconds at 22050Hz/256 hop
    max_text_length: 100  # Maximum phoneme sequence length

# Model configuration with scaling factors
model:
  # Global scaling factors - modify these to resize the entire model
  scale_factors:
    base_channels: 64    # Base number of channels to scale from
    latent_dim: 16       # Latent dimension size
    depth_factor: 1      # Multiplier for network depth

  # Conditioning encoder
  conditioning:
    # Feature dimensions
    f0_embedding_dim: 64           # Will be 64
    phone_embedding_dim: 128       # Will be 128
    midi_embedding_dim: 64         # Will be 64
    duration_embedding_dim: 32     # Will be 32
    
    # Network parameters
    hidden_channels: 128           # Will be 128
    n_layers: 2                    # At least 2 layers
    kernel_size: 3
    dropout: 0.1
    
    # Additional options
    use_pos_encoding: true
    cross_attention: true
    cross_attention_heads: 4

  # VAE configuration
  vae:
    # Dimensions
    encoder_channels: [64, 128, 256]  # [base, base*2, base*4]
    decoder_channels: [256, 128, 64]  # [base*4, base*2, base]
    latent_channels: 128              # Will be 128
    latent_dim: 16                    # Will be 16
    
    # Training parameters
    kl_weight:
      initial: 0.001
      target: 0.01
      anneal_steps: 50000
      
    # Reconstruction options
    use_spectral_norm: true
    use_residual_blocks: true
    
  # Diffusion model configuration
  diffusion:
    # Diffusion process
    diffusion_steps: 1000
    diffusion_schedule: cosine  # Options: linear, cosine, quadratic
    beta_start: 0.0001
    beta_end: 0.02
    
    # UNet configuration
    unet:
      base_channels: 128            # Will be 128
      channel_multipliers: [1, 2, 4]  # Relative to base_channels
      num_res_blocks: 2             # At least 2 res blocks per level
      attention_levels: [1, 2]      # Which levels have attention
      num_heads: 4
      use_scale_shift_norm: true
      dropout: 0.1
    
    # Conditioning options
    conditioning_mode: cross_attention  # Options: cross_attention, concat, adagn
    prediction_type: epsilon  # Options: epsilon, x0, v

# Training configurations
training:
  # Common parameters
  batch_size: 16
  num_epochs: 100
  gradient_clip_val: 1.0
  precision: 16-mixed
  seed: 42
  
  # Optimizer
  optimizer:
    name: adamw  # Options: adam, adamw
    learning_rate: 0.0005
    weight_decay: 0.0001
    beta1: 0.9
    beta2: 0.999
    
  # Learning rate scheduler
  scheduler:
    name: cosine  # Options: cosine, step, plateau, none
    warmup_steps: 1000
    decay_steps: 200000
    min_lr_ratio: 0.1
    
  # Training mode
  mode: joint  # Options: vae_only, diffusion_only, joint
  
  # Mode-specific settings
  vae_training:
    batch_size: 32  # Can be larger since VAE is simpler
    learning_rate: 0.001
    kl_schedule: true
    
  diffusion_training:
    batch_size: 16
    learning_rate: 0.0002
    condition_dropout: 0.1  # Randomly drop conditioning for classifier-free guidance
    freeze_vae: true
    
  joint_training:
    vae_weight: 0.1
    diffusion_weight: 1.0
    
  # Validation
  val_interval: 1000  # Validation every N steps
  val_max_samples: 8  # Number of validation samples to process
  
  # Checkpoints and logging
  save_dir: logs/latent_diffusion
  checkpoint_interval: 5000
  log_interval: 100
  log_images: true
  num_visualization_samples: 4
  
  # Hardware
  num_workers: 4
  pin_memory: true
  
# Inference configuration
inference:
  # Sampling parameters
  num_steps: 50     # Can be less than training steps for faster inference
  guidance_scale: 3.0  # For classifier-free guidance
  temperature: 1.0
  
  # Generation options
  auto_resize: true  # Resize outputs to match input timing
  normalize_output: true
  
  # Vocoder (optional integration with external vocoder)
  vocoder:
    type: none  # Options: hifigan, waveglow, none
    checkpoint: null